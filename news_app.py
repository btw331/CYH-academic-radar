# ==========================================
# 0. å„ªå…ˆåŸ·è¡Œï¼šè­¦å‘Šå±è”½èˆ‡å¥—ä»¶è¨­å®š
# ==========================================
import warnings
import os
warnings.filterwarnings("ignore")
os.environ["on_bad_lines"] = "skip"

import streamlit as st
import re
import pandas as pd
import time
import requests
import json
from urllib.parse import urlparse
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_exponential
import plotly.express as px
import plotly.graph_objects as go

# ==========================================
# 1. åŸºç¤è¨­å®šèˆ‡ CSSæ¨£å¼
# ==========================================
st.set_page_config(page_title="å…¨åŸŸè§€é»æœå°‹ V13", page_icon="âš–ï¸", layout="wide")

st.markdown("""
<style>
    .metric-container {
        text-align: center;
        padding: 15px;
        background-color: #ffffff;
        border-radius: 8px;
        border: 1px solid #f0f0f0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        transition: transform 0.2s;
    }
    .metric-container:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    .metric-score { font-size: 2.8em; font-weight: 700; margin: 0; line-height: 1.2;}
    .metric-label { font-size: 1.0em; font-weight: 500; margin-top: 5px; color: #666; letter-spacing: 1px; }
    
    .stButton button[kind="secondary"] { border: 2px solid #673ab7; color: #673ab7; font-weight: bold; }
    
    .fact-check-box {
        background-color: #e8f5e9; border: 1px solid #c8e6c9; border-radius: 8px; padding: 15px; margin-bottom: 20px;
    }
    .fact-check-title { color: #2e7d32; font-weight: bold; font-size: 1.1em; display: flex; align-items: center; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. è³‡æ–™åº«èˆ‡å…±ç”¨å¸¸æ•¸ (ä¿ç•™åŸæœ‰ DB_MAP)
# ==========================================
DB_MAP = {
    "CHINA": ["xinhuanet.com", "people.com.cn", "huanqiu.com", "cctv.com", "chinadaily.com.cn", "cgtn.com", "taiwan.cn", "gwytb.gov.cn", "guancha.cn", "thepaper.cn", "sina.com.cn", "163.com", "sohu.com", "ifeng.com", "crntt.com", "hk01.com"],
    "JAPAN": ["nhk.or.jp", "asia.nikkei.com", "yomiuri.co.jp", "asahi.com", "japantimes.co.jp", "mainichi.jp", "sankei.com"],
    "INTL": ["reuters.com", "apnews.com", "bloomberg.com", "wsj.com", "ft.com", "economist.com", "bbc.com", "dw.com", "voanews.com", "thediplomat.com", "foreignpolicy.com", "guardian.co.uk", "aljazeera.com", "rfi.fr", "nytimes.com", "cnn.com", "csis.org"],
    "DIGITAL": ["twreporter.org", "theinitium.com", "storm.mg", "upmedia.mg", "mindiworldnews.com", "allsides.com", "ground.news", "thenewslens.com", "readr.tw", "vocus.cc"],
    "OFFICIAL": ["cna.com.tw", "pts.org.tw", "mnd.gov.tw", "indsr.org.tw", "tfc-taiwan.org.tw", "mygopen.com", "cofacts.tw", "mac.gov.tw"],
    "GREEN": ["ltn.com.tw", "ftvnews.com.tw", "setn.com", "rti.org.tw", "newtalk.tw", "peoplenews.tw", "mirrormedia.mg", "dpp.org.tw"],
    "BLUE": ["udn.com", "chinatimes.com", "tvbs.com.tw", "cti.com.tw", "coolloud.org.tw", "nownews.com", "ctee.com.tw", "want-daily.com", "kmt.org.tw"],
    "FARM": ["kknews.cc", "read01.com", "ppfocus.com", "buzzhand.com", "bomb01.com", "qiqi.news", "lackk.com", "mission-tw.com", "hottopic.com", "weibo.com", "xuehua.us", "inf.news", "toutiao.com", "baidu.com", "ptt.cc", "dcard.tw", "mobile01.com"],
    "VIDEO": ["youtube.com", "youtu.be", "tiktok.com", "douyin.com", "bilibili.com", "ixigua.com"],
    "AGGREGATOR": ["yahoo.com", "msn.com", "linetoday.com", "google.com", "ettoday.net"]
}

NAME_KEYWORDS = {
    "CHINA": ["æ–°è¯", "äººæ°‘æ—¥å ±", "ç’°çƒ", "å¤®è¦–", "åœ‹å°è¾¦", "ä¸­è©•", "è§£æ”¾è»", "é™¸åª’", "åŒ—äº¬", "å®‹æ¿¤", "xinhuanet", "huanqiu"],
    "GREEN": ["è‡ªç”±", "ä¸‰ç«‹", "æ°‘è¦–", "æ–°é ­æ®¼", "é¡é€±åˆŠ", "æ°‘é€²é»¨", "è³´æ¸…å¾·", "ç¶ ç‡Ÿ", "ç¨æ´¾", "æŠ—ä¸­ä¿å°", "ltn", "setn", "ftv"],
    "BLUE": ["è¯åˆ", "ä¸­åœ‹æ™‚å ±", "ä¸­æ™‚", "TVBS", "ä¸­å¤©", "å·¥å•†æ™‚å ±", "æ—ºæ—º", "åœ‹æ°‘é»¨", "KMT", "ä¾¯å‹å®œ", "è—ç‡Ÿ", "çµ±æ´¾", "udn", "chinatimes"],
    "FARM": ["ç¶²å‚³", "è¬ è¨€", "çˆ†æ–™", "å…§å®¹è¾²å ´", "PTT", "Dcard", "çˆ†æ–™å…¬ç¤¾"],
    "OFFICIAL": ["ä¸­å¤®ç¤¾", "å…¬è¦–", "cna", "pts", "gov"],
    "VIDEO": ["YouTube", "YouTuber", "ç¶²ç´…", "TikTok", "æŠ–éŸ³", "é¤¨é•·", "ç›´æ’­"]
}

def get_domain_name(url):
    try: return urlparse(url).netloc.replace("www.", "")
    except: return ""

def classify_media_name(name):
    n = name.lower()
    for cat, keywords in NAME_KEYWORDS.items():
        if any(k in n for k in keywords): return cat
    return "OTHER"

def get_category_meta(cat):
    meta = {
        "CHINA": ("ğŸ‡¨ğŸ‡³ ä¸­åœ‹å®˜åª’", "#d32f2f"),
        "FARM": ("â›” å…§å®¹è¾²å ´", "#ef6c00"),
        "BLUE": ("ğŸ”µ æ³›è—è§€é»", "#1565c0"),
        "GREEN": ("ğŸŸ¢ æ³›ç¶ è§€é»", "#2e7d32"),
        "OFFICIAL": ("âšª å®˜æ–¹/ä¸­ç«‹", "#546e7a"),
        "AGGREGATOR": ("ğŸŒ å…¥å£ç¶²ç«™", "#607d8b"),
        "JAPAN": ("ğŸ‡¯ğŸ‡µ æ—¥æœ¬è§€é»", "#f57c00"),
        "INTL": ("ğŸŒ åœ‹éš›åª’é«”", "#f57c00"),
        "DIGITAL": ("ğŸŸ¡ æ•¸ä½/ç¶²åª’", "#fbc02d"),
        "VIDEO": ("ğŸŸ£ å½±éŸ³ç¤¾ç¾¤", "#7b1fa2"),
        "OTHER": ("ğŸ“„ å…¶ä»–ä¾†æº", "#9e9e9e")
    }
    return meta.get(cat, ("å…¶ä»–", "#9e9e9e"))

def get_score_text_color(score):
    if score >= 80: return "#d32f2f"
    if score >= 60: return "#e65100"
    if score >= 40: return "#f57f17"
    if score >= 20: return "#388e3c"
    return "#757575"

# ==========================================
# 3. åŠŸèƒ½æ¨¡çµ„ï¼šCofacts & Gemini
# ==========================================

# [NEW] Cofacts API æŸ¥è©¢åŠŸèƒ½
def search_cofacts(query):
    url = "https://cofacts-api.g0v.tw/graphql"
    # GraphQL æŸ¥è©¢èªæ³•
    graphql_query = """
    query ListArticles($text: String!) {
      ListArticles(filter: {q: $text}, orderBy: [{_score: DESC}], first: 3) {
        edges {
          node {
            text
            articleReplies(status: NORMAL) {
              reply {
                text
                type
              }
            }
          }
        }
      }
    }
    """
    try:
        response = requests.post(url, json={'query': graphql_query, 'variables': {'text': query}}, timeout=5)
        if response.status_code == 200:
            data = response.json()
            articles = data.get('data', {}).get('ListArticles', {}).get('edges', [])
            result_text = ""
            if articles:
                result_text += "ã€Cofacts çœŸçš„å‡çš„ - æŸ¥æ ¸è³‡æ–™åº«çµæœã€‘\n"
                for i, art in enumerate(articles):
                    node = art.get('node', {})
                    rumor_text = node.get('text', '')[:100]
                    replies = node.get('articleReplies', [])
                    if replies:
                        for rep in replies:
                            r = rep.get('reply', {})
                            r_type = r.get('type')
                            r_text = r.get('text', '')[:200]
                            # è½‰æ›é¡å‹ç‚ºæ˜“è®€æ–‡å­—
                            type_map = {"RUMOR": "âŒ å«æœ‰ä¸å¯¦è³‡è¨Š", "NOT_ARTICLE": "â­• æŸ¥ç„¡ä¸å¯¦/å€‹äººæ„è¦‹", "OPINION": "ğŸ’¬ ç´”å±¬æ„è¦‹"}
                            display_type = type_map.get(r_type, r_type)
                            result_text += f"- ç¶²å‚³è¬ è¨€: {rumor_text}...\n  -> æŸ¥æ ¸çµæœ: {display_type} | èªªæ˜: {r_text}...\n"
            return result_text
    except Exception as e:
        return f"Cofacts æŸ¥è©¢å¤±æ•—: {str(e)}"
    return ""

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10), reraise=True)
def call_gemini_with_retry(chain, input_data):
    return chain.invoke(input_data)

def run_fusion_analysis(query, api_key_google, api_key_tavily, model_name, mode="FUSION", context_report=None):
    os.environ["GOOGLE_API_KEY"] = api_key_google
    os.environ["TAVILY_API_KEY"] = api_key_tavily
    
    try:
        # 1. æœå°‹éšæ®µ (Tavily + Cofacts)
        results = None
        context_text = ""
        
        # [NEW] åŒæ­¥åŸ·è¡Œ Cofacts æŸ¥è©¢
        cofacts_result = search_cofacts(query)
        if cofacts_result:
            context_text += f"\n{cofacts_result}\n" + "="*30 + "\n"

        search = TavilySearchResults(max_results=20) 
        
        if context_report and len(context_report) > 50:
            context_text += f"ã€å‰æ¬¡åˆ†æå ±å‘Šã€‘\n{context_report}\n\nã€ä»Šæ—¥æœ€æ–°æƒ…å ±ã€‘\n"
            q_mix = f"{query} 2025 æœ€æ–°ç™¼å±•"
        else:
            q_mix = f"{query} 2025 æœ€æ–° å°ç£æ–°è çˆ­è­° æ‡¶äººåŒ… è©•è«–"

        results = search.invoke(q_mix)
        for i, res in enumerate(results):
            context_text += f"Source {i+1}: {res.get('url')} | {str(res.get('content'))[:2000]}\n"

        # 2. æ€è€ƒéšæ®µ (Prompt Engineering)
        # [NEW] åŠ å…¥è¼¿è«–å…‰è­œ (Spectrum) èˆ‡ å‹•æ…‹ä¾†æºåˆ†é¡ æŒ‡ä»¤
        system_prompt = f"""
        ä½ æ˜¯ä¸€ä½å…¨åŸŸæƒ…å ±åˆ†æå¸«ã€‚è«‹é‡å°ã€Œ{query}ã€é€²è¡Œæ·±åº¦è§£æã€‚
        
        ã€ä»»å‹™ 1: çœŸå¯¦æ€§é©—è­‰ã€‘
        è«‹å„ªå…ˆåƒè€ƒæä¾›çš„ã€Cofacts æŸ¥æ ¸è³‡æ–™ã€‘ã€‚è‹¥æœ‰æ˜ç¢ºæŸ¥æ ¸å ±å‘Šï¼Œè«‹åœ¨å ±å‘Šé–‹é ­ä»¥ã€Œâš ï¸ æŸ¥æ ¸è­¦ç¤ºã€æ¨™è¨»ã€‚
        
        ã€ä»»å‹™ 2: è¼¿è«–å…‰è­œå®šä½ (Spectrum Mapping)ã€‘
        è«‹åˆ†ææ¯å€‹ä¾†æºçš„ã€Œæ”¿æ²»ç«‹å ´ã€èˆ‡ã€Œå¯ä¿¡åº¦ã€ã€‚
        - ç«‹å ´ (Xè»¸): -10(æ·±ç¶ /ç¨æ´¾) <-> 0(ä¸­ç«‹) <-> 10(æ·±è—/çµ±æ´¾/ç´…)
        - å¯ä¿¡åº¦ (Yè»¸): 0(å…§å®¹è¾²å ´/å‡è¨Šæ¯) <-> 10(æ¬Šå¨åª’é«”/å®˜æ–¹æ•¸æ“š)
        
        ã€ä»»å‹™ 3: å‹•æ…‹ä¾†æºè­˜åˆ¥ã€‘
        è‹¥é‡åˆ°éçŸ¥åç¶²åŸŸï¼Œè«‹æ ¹æ“šå…¶æ¨™é¡Œé¢¨æ ¼ï¼ˆå¦‚æ¨™é¡Œæ®ºäººæ³•ã€è¾²å ´æ–‡é«”ï¼‰é€²è¡Œå‹•æ…‹æ¨™è¨˜ã€‚

        ã€è¼¸å‡ºæ ¼å¼ (åš´æ ¼éµå®ˆ)ã€‘ï¼š
        ### [DATA_SCORES]
        Threat: [0-100]
        Attack: [0-100]
        Impact: [0-100]
        Division: [0-100]
        Resilience: [0-100]
        
        ### [DATA_TIMELINE]
        (æ ¼å¼ï¼šYYYY-MM-DD|åª’é«”|æ¨™é¡Œ)
        
        ### [DATA_SPECTRUM]
        (æ ¼å¼ï¼šä¾†æºåç¨±|ç«‹å ´åˆ†æ•¸(-10~10)|å¯ä¿¡åº¦åˆ†æ•¸(0~10)|ç¶²å€)
        Example:
        æ–°è¯ç¤¾|10|4|http://...
        è‡ªç”±æ™‚å ±|-8|7|http://...
        PTTç¶²å‹|0|2|http://...

        ### [REPORT_TEXT]
        (Markdown å ±å‘Š)
        è«‹åŒ…å«ï¼š
        1. **ğŸ“Š å…¨åŸŸç¾æ³æ‘˜è¦** (å« Cofacts æŸ¥æ ¸çµæœ)
        2. **âš–ï¸ è¼¿è«–å…‰è­œåˆ†æ** (è§£è®€å…‰è­œåˆ†ä½ˆçš„æ„ç¾©ï¼šæ˜¯æ¥µåŒ–å°ç«‹é‚„æ˜¯å…±è­˜ï¼Ÿ)
        3. **ğŸ” æ·±åº¦è­˜è®€èˆ‡åˆ©ç›Šåˆ†æ**
        """

        llm = ChatGoogleGenerativeAI(model=model_name, temperature=0.1)
        prompt = ChatPromptTemplate.from_messages([("system", system_prompt), ("human", "{context_text}")])
        chain = prompt | llm
        response = call_gemini_with_retry(chain, {"context_text": context_text})
        return response.content, results, cofacts_result

    except Exception as e:
        if "429" in str(e): return "API_LIMIT_ERROR", None, None
        return f"ERROR: {str(e)}", None, None

def parse_gemini_data(text):
    data = {"scores": {"Threat":0, "Attack":0, "Impact":0, "Division":0, "Resilience":0}, 
            "timeline": [], "spectrum": [], "report_text": ""}
    
    if not text or text.startswith("ERROR"):
        data["report_text"] = text
        return data

    for line in text.split('\n'):
        line = line.strip()
        # Parse Scores
        for key in data["scores"]:
            if f"{key}:" in line:
                try: data["scores"][key] = int(re.search(r'\d+', line).group())
                except: pass
        
        # Parse Timeline
        if "|" in line and len(line.split("|")) >= 3 and (line[0].isdigit() or "Future" in line):
            parts = line.split("|")
            data["timeline"].append({"date": parts[0].strip(), "media": parts[1].strip(), "event": parts[2].strip()})
            
        # [NEW] Parse Spectrum
        # Logic: æ’é™¤ timeline (é€šå¸¸æœ‰æ—¥æœŸ) å’Œ headerï¼ŒæŠ“å– 4 å€‹æ¬„ä½çš„è³‡æ–™
        if "|" in line and len(line.split("|")) >= 4 and not line.startswith("###") and not "æ—¥æœŸ" in line:
            parts = line.split("|")
            try:
                data["spectrum"].append({
                    "source": parts[0].strip(),
                    "stance": float(parts[1].strip()),
                    "credibility": float(parts[2].strip()),
                    "url": parts[3].strip()
                })
            except: pass

    # Parse Report Text
    if "### [REPORT_TEXT]" in text:
        data["report_text"] = text.split("### [REPORT_TEXT]")[1].strip()
    elif "### REPORT_TEXT" in text:
        data["report_text"] = text.split("### REPORT_TEXT")[1].strip()
    else:
        # Fallback extraction
        match = re.search(r"(#+\s*.*æ‘˜è¦|1\.\s*.*æ‘˜è¦)", text)
        if match: data["report_text"] = text[match.start():]
        else: data["report_text"] = text

    return data

def render_spectrum_chart(spectrum_data):
    if not spectrum_data: return None
    
    df = pd.DataFrame(spectrum_data)
    
    # å»ºç«‹æ•£å¸ƒåœ–
    fig = px.scatter(
        df, 
        x="stance", 
        y="credibility", 
        hover_name="source",
        text="source",
        size=[15]*len(df), # å›ºå®šé»å¤§å°
        color="stance",
        color_continuous_scale=["#2e7d32", "#eeeeee", "#d32f2f"], # ç¶  -> ç™½ -> ç´…
        range_x=[-11, 11],
        range_y=[-1, 11],
        labels={"stance": "æ”¿æ²»ç«‹å ´ (ç¶  <-> è—/ç´…)", "credibility": "å¯ä¿¡åº¦/å°ˆæ¥­åº¦"},
        title="è¼¿è«–å…‰è­œåˆ†ä½ˆåœ– (AI å‹•æ…‹åˆ¤å®š)"
    )
    
    # åŠ å…¥è±¡é™èƒŒæ™¯èˆ‡æ¨™è¨»
    fig.add_shape(type="rect", x0=-11, y0=5, x1=0, y1=11, fillcolor="rgba(46, 125, 50, 0.1)", layer="below", line_width=0) # ç¶ ç‡Ÿæ¬Šå¨
    fig.add_shape(type="rect", x0=0, y0=5, x1=11, y1=11, fillcolor="rgba(21, 101, 192, 0.1)", layer="below", line_width=0) # è—ç‡Ÿæ¬Šå¨
    fig.add_shape(type="rect", x0=-11, y0=-1, x1=11, y1=5, fillcolor="rgba(255, 167, 38, 0.1)", layer="below", line_width=0) # è¾²å ´/ä½å¯ä¿¡
    
    fig.update_layout(
        xaxis_title="â—€ æ³›ç¶ è§€é» --------- ä¸­ç«‹ --------- æ³›è—/å®˜æ–¹è§€é» â–¶",
        yaxis_title="å¯ä¿¡åº¦ (ä½ -> é«˜)",
        showlegend=False,
        height=500
    )
    fig.update_traces(textposition='top center')
    
    return fig

# ==========================================
# 4. ä»‹é¢ (UI)
# ==========================================
with st.sidebar:
    st.title("å…¨åŸŸæƒ…å ±ä¸­å¿ƒ V13")
    st.caption("æ ¸å¿ƒï¼šCofacts æŸ¥æ ¸ + è¼¿è«–å…‰è­œ + å‹•æ…‹è­˜åˆ¥")
    
    with st.expander("ğŸ”‘ ç³»çµ±è¨­å®š", expanded=True):
        if "GOOGLE_API_KEY" in st.secrets:
            st.success("âœ… Gemini Key Ready")
            google_key = st.secrets["GOOGLE_API_KEY"]
        else:
            google_key = st.text_input("Gemini Key", type="password")

        if "TAVILY_API_KEY" in st.secrets:
            st.success("âœ… Tavily Key Ready")
            tavily_key = st.secrets["TAVILY_API_KEY"]
        else:
            tavily_key = st.text_input("Tavily Key", type="password")
            
        model_name = st.selectbox("æ¨¡å‹", ["gemini-2.5-flash", "gemini-2.5-pro"], index=0)

    # æ­·å²å ±å‘ŠåŒ¯å…¥å€
    with st.expander("ğŸ“‚ æ»¾å‹•å¼è¿½è¹¤ (åŒ¯å…¥èˆŠå ±å‘Š)", expanded=False):
        past_report_input = st.text_area("è²¼ä¸Šä¹‹å‰çš„ Markdown å ±å‘Šï¼š", height=100)

# ä¸»ç•«é¢
st.title("âš–ï¸ å…¨åŸŸè§€é»æœå°‹ (Full Spectrum)")
query = st.text_input("è¼¸å…¥è­°é¡Œé—œéµå­—", placeholder="ä¾‹å¦‚ï¼šå°ç©é›»ç¾åœ‹è¨­å» çˆ­è­°")
search_btn = st.button("ğŸš€ å•Ÿå‹•å…¨åŸŸæƒæ", type="primary")

if 'result' not in st.session_state: st.session_state.result = None
if 'cofacts' not in st.session_state: st.session_state.cofacts = None

if search_btn and query:
    st.session_state.result = None 
    st.session_state.cofacts = None
    
    with st.spinner("ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨èª¿é–± Cofacts æŸ¥æ ¸è³‡æ–™åº« & æƒæå…¨ç¶²è¼¿è«–..."):
        report_context = past_report_input if past_report_input.strip() else None
        
        raw_text, sources, cofacts_txt = run_fusion_analysis(query, google_key, tavily_key, model_name, context_report=report_context)
        
        parsed_data = parse_gemini_data(raw_text)
        st.session_state.result = parsed_data
        st.session_state.cofacts = cofacts_txt
        st.rerun()

if st.session_state.result:
    data = st.session_state.result
    
    # 1. é¡¯ç¤ºæŸ¥æ ¸çµæœ (å¦‚æœæœ‰)
    if st.session_state.cofacts:
        st.markdown(f"""
        <div class="fact-check-box">
            <div class="fact-check-title">ğŸ›¡ï¸ Cofacts çœŸçš„å‡çš„ - è‡ªå‹•æŸ¥æ ¸è­¦ç¤º</div>
            <div style="white-space: pre-wrap; margin-top: 10px; font-size: 0.9em;">{st.session_state.cofacts}</div>
        </div>
        """, unsafe_allow_html=True)

    # 2. æ ¸å¿ƒæŒ‡æ¨™
    scores = data.get("scores", {})
    c1, c2, c3, c4 = st.columns(4)
    metrics = [("å‚³æ’­ç†±åº¦", scores.get("Attack", 0)), ("è§€é»åˆ†æ­§", scores.get("Division", 0)),
               ("å½±éŸ¿æ½›åŠ›", scores.get("Impact", 0)), ("è³‡è¨Šé€æ˜", scores.get("Resilience", 0))]
    
    for col, (label, score) in zip([c1, c2, c3, c4], metrics):
        col.markdown(f"""
        <div class="metric-container">
            <p class="metric-score" style="color: {get_score_text_color(score)};">{score}</p>
            <p class="metric-label">{label}</p>
        </div>
        """, unsafe_allow_html=True)

    # 3. [NEW] è¼¿è«–å…‰è­œåœ– (Plotly)
    st.markdown("---")
    st.subheader("ğŸ—ºï¸ è¼¿è«–é™£åœ°å…‰è­œ (AI å‹•æ…‹è­˜åˆ¥)")
    st.caption("Xè»¸ï¼šæ”¿æ²»ç«‹å ´ (å·¦ç¶ /å³è—) | Yè»¸ï¼šè³‡è¨Šå¯ä¿¡åº¦ (ä¸Šé«˜/ä¸‹ä½)")
    if data["spectrum"]:
        fig = render_spectrum_chart(data["spectrum"])
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("å°šç„¡è¶³å¤ è³‡æ–™ç¹ªè£½å…‰è­œåœ–ã€‚")

    # 4. åˆ†æå ±å‘Š
    st.markdown("---")
    st.subheader("ğŸ“ æ·±åº¦åˆ†æå ±å‘Š")
    st.markdown(data.get("report_text", "ç„¡åˆ†æå ±å‘Šã€‚"))
    
    # 5. æ™‚é–“è»¸
    st.markdown("---")
    with st.expander("ğŸ“… é—œéµç™¼å±•æ™‚åºè¡¨"):
        if data["timeline"]:
            st.dataframe(pd.DataFrame(data["timeline"]), width='stretch', hide_index=True)
