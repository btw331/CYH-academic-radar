# ==========================================
# 0. å„ªå…ˆåŸ·è¡Œï¼šè­¦å‘Šå±è”½èˆ‡å¥—ä»¶è¨­å®š
# ==========================================
import warnings
import os
warnings.filterwarnings("ignore")
os.environ["on_bad_lines"] = "skip"

import streamlit as st
import re
import pandas as pd
import time
from urllib.parse import urlparse
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_exponential

# ==========================================
# 1. åŸºç¤è¨­å®šèˆ‡ CSSæ¨£å¼
# ==========================================
st.set_page_config(page_title="å…¨åŸŸè§€é»æœå°‹", page_icon="âš–ï¸", layout="wide")

st.markdown("""
<style>
    .metric-container {
        text-align: center;
        padding: 15px;
        background-color: #ffffff;
        border-radius: 8px;
        border: 1px solid #f0f0f0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        transition: transform 0.2s;
    }
    .metric-container:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    .metric-score { font-size: 2.8em; font-weight: 700; margin: 0; line-height: 1.2;}
    .metric-label { font-size: 1.0em; font-weight: 500; margin-top: 5px; color: #666; letter-spacing: 1px; }
    
    /* æ»¾å‹•æŒ‰éˆ•æ¨£å¼ */
    .stButton button[kind="secondary"] {
        border: 2px solid #673ab7;
        color: #673ab7;
        font-weight: bold;
    }
    
    /* ä¾†æºé€£çµæ¨£å¼ */
    .source-block-container {
        padding: 10px;
        border-radius: 6px;
        margin-bottom: 10px;
        color: white;
    }
    .source-block-title { font-weight: 600; margin-bottom: 6px; display: block; font-size: 0.95em; opacity: 0.95; }
    
    .source-link { 
        color: white !important; 
        text-decoration: none; 
        margin: 3px 0; 
        display: block; 
        background-color: rgba(255,255,255,0.15); 
        padding: 4px 8px; 
        border-radius: 4px;
        font-size: 0.8em;
        transition: background-color 0.2s;
        white-space: nowrap; 
        overflow: hidden; 
        text-overflow: ellipsis;
    }
    .source-link:hover {
        background-color: rgba(255,255,255,0.3);
        text-decoration: none;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. è³‡æ–™åº«èˆ‡å…±ç”¨å¸¸æ•¸
# ==========================================
DB_MAP = {
    "CHINA": ["xinhuanet.com", "people.com.cn", "huanqiu.com", "cctv.com", "chinadaily.com.cn", "cgtn.com", "taiwan.cn", "gwytb.gov.cn", "guancha.cn", "thepaper.cn", "sina.com.cn", "163.com", "sohu.com", "ifeng.com", "crntt.com", "hk01.com"],
    "JAPAN": ["nhk.or.jp", "asia.nikkei.com", "yomiuri.co.jp", "asahi.com", "japantimes.co.jp", "mainichi.jp", "sankei.com"],
    "INTL": ["reuters.com", "apnews.com", "bloomberg.com", "wsj.com", "ft.com", "economist.com", "bbc.com", "dw.com", "voanews.com", "thediplomat.com", "foreignpolicy.com", "guardian.co.uk", "aljazeera.com", "rfi.fr", "nytimes.com", "cnn.com", "csis.org"],
    "DIGITAL": ["twreporter.org", "theinitium.com", "storm.mg", "upmedia.mg", "mindiworldnews.com", "allsides.com", "ground.news", "thenewslens.com", "readr.tw", "vocus.cc"],
    "OFFICIAL": ["cna.com.tw", "pts.org.tw", "mnd.gov.tw", "indsr.org.tw", "tfc-taiwan.org.tw", "mygopen.com", "cofacts.tw", "mac.gov.tw"],
    "GREEN": ["ltn.com.tw", "ftvnews.com.tw", "setn.com", "rti.org.tw", "newtalk.tw", "peoplenews.tw", "mirrormedia.mg", "dpp.org.tw"],
    "BLUE": ["udn.com", "chinatimes.com", "tvbs.com.tw", "cti.com.tw", "coolloud.org.tw", "nownews.com", "ctee.com.tw", "want-daily.com", "kmt.org.tw"],
    "FARM": ["kknews.cc", "read01.com", "ppfocus.com", "buzzhand.com", "bomb01.com", "qiqi.news", "lackk.com", "mission-tw.com", "hottopic.com", "weibo.com", "xuehua.us", "inf.news", "toutiao.com", "baidu.com", "ptt.cc", "dcard.tw", "mobile01.com"],
    "VIDEO": ["youtube.com", "youtu.be", "tiktok.com", "douyin.com", "bilibili.com", "ixigua.com"],
    "AGGREGATOR": ["yahoo.com", "msn.com", "linetoday.com", "google.com", "ettoday.net"]
}

NAME_KEYWORDS = {
    "CHINA": ["æ–°è¯", "äººæ°‘æ—¥å ±", "ç’°çƒ", "å¤®è¦–", "åœ‹å°è¾¦", "ä¸­è©•", "è§£æ”¾è»", "é™¸åª’", "åŒ—äº¬", "å®‹æ¿¤", "xinhuanet", "huanqiu"],
    "GREEN": ["è‡ªç”±", "ä¸‰ç«‹", "æ°‘è¦–", "æ–°é ­æ®¼", "é¡é€±åˆŠ", "æ°‘é€²é»¨", "è³´æ¸…å¾·", "ç¶ ç‡Ÿ", "ç¨æ´¾", "æŠ—ä¸­ä¿å°", "ltn", "setn", "ftv"],
    "BLUE": ["è¯åˆ", "ä¸­åœ‹æ™‚å ±", "ä¸­æ™‚", "TVBS", "ä¸­å¤©", "å·¥å•†æ™‚å ±", "æ—ºæ—º", "åœ‹æ°‘é»¨", "KMT", "ä¾¯å‹å®œ", "è—ç‡Ÿ", "çµ±æ´¾", "udn", "chinatimes"],
    "FARM": ["ç¶²å‚³", "è¬ è¨€", "çˆ†æ–™", "å…§å®¹è¾²å ´", "PTT", "Dcard", "çˆ†æ–™å…¬ç¤¾"],
    "OFFICIAL": ["ä¸­å¤®ç¤¾", "å…¬è¦–", "cna", "pts", "gov"],
    "VIDEO": ["YouTube", "YouTuber", "ç¶²ç´…", "TikTok", "æŠ–éŸ³", "é¤¨é•·", "ç›´æ’­"]
}

NARRATIVE_MODULES_LIST = [
    "ç–‘ç¾è«–/åœ‹éš›å­¤ç«‹è«–", "æˆ°çˆ­ææ‡¼/å…©å²¸ç·Šå¼µ", "æ–½æ”¿çˆ­è­°/æ²»ç†èƒ½åŠ›", "æ–‡åŒ–èªåŒ/æ°‘æ—æƒ…æ„Ÿ",
    "è»åŠ›æ‡¸æ®Š/æŠ•é™ä¸»ç¾©", "ç¶“æ¿Ÿä¾è³´/æƒ å°æªæ–½", "æ³•å¾‹æˆ°/ä¸»æ¬Šçˆ­è­°", "é«”åˆ¶å„ªè¶Šè«–", "å…§éƒ¨å”åŠ›/æ”¿æ²»æ”»é˜²"
]
NARRATIVE_MODULES_STR = "\n".join([f"{i+1}. {m}" for i, m in enumerate(NARRATIVE_MODULES_LIST)])

def get_domain_name(url):
    try: return urlparse(url).netloc.replace("www.", "")
    except: return ""

def classify_media_name(name):
    n = name.lower()
    for cat, keywords in NAME_KEYWORDS.items():
        if any(k in n for k in keywords): return cat
    return "OTHER"

def get_category_meta(cat):
    meta = {
        "CHINA": ("ğŸ‡¨ğŸ‡³ ä¸­åœ‹å®˜åª’", "#d32f2f"),
        "FARM": ("â›” å…§å®¹è¾²å ´", "#ef6c00"),
        "BLUE": ("ğŸ”µ æ³›è—è§€é»", "#1565c0"),
        "GREEN": ("ğŸŸ¢ æ³›ç¶ è§€é»", "#2e7d32"),
        "OFFICIAL": ("âšª å®˜æ–¹/ä¸­ç«‹", "#546e7a"),
        "AGGREGATOR": ("ğŸŒ å…¥å£ç¶²ç«™", "#607d8b"),
        "JAPAN": ("ğŸ‡¯ğŸ‡µ æ—¥æœ¬è§€é»", "#f57c00"),
        "INTL": ("ğŸŒ åœ‹éš›åª’é«”", "#f57c00"),
        "DIGITAL": ("ğŸŸ¡ æ•¸ä½/ç¶²åª’", "#fbc02d"),
        "VIDEO": ("ğŸŸ£ å½±éŸ³ç¤¾ç¾¤", "#7b1fa2"),
        "OTHER": ("ğŸ“„ å…¶ä»–ä¾†æº", "#9e9e9e")
    }
    return meta.get(cat, ("å…¶ä»–", "#9e9e9e"))

def classify_source(url):
    url_str = url.lower()
    for cat, keywords in DB_MAP.items():
        for kw in keywords:
            if kw in url_str: return cat
    return "OTHER"

def get_category_info(cat):
    return get_category_meta(cat)[0], get_category_meta(cat)[1], "ğŸ“„"

def get_score_text_color(score):
    if score >= 80: return "#d32f2f"
    if score >= 60: return "#e65100"
    if score >= 40: return "#f57f17"
    if score >= 20: return "#388e3c"
    return "#757575"

# ==========================================
# 3. é›™æ ¸èåˆåˆ†æå¼•æ“
# ==========================================

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10), reraise=True)
def call_gemini_with_retry(chain, input_data):
    return chain.invoke(input_data)

def run_fusion_analysis(query, api_key_google, api_key_tavily, model_name, mode="FUSION", context_report=None):
    os.environ["GOOGLE_API_KEY"] = api_key_google
    os.environ["TAVILY_API_KEY"] = api_key_tavily
    
    try:
        # 1. æœå°‹éšæ®µ
        results = None
        context_text = ""
        
        if context_report and len(context_report) > 50:
            # æ»¾å‹•æ¨¡å¼ï¼šä½¿ç”¨åŒ¯å…¥çš„æ­·å²å ±å‘Š + æ–°æœå°‹
            context_text = f"ã€å‰æ¬¡åˆ†æå ±å‘Š (æ­·å²èƒŒæ™¯)ã€‘\n{context_report}\n\nã€ä»Šæ—¥æœ€æ–°æƒ…å ±ã€‘\n"
            task_instruction = f"ä½ å·²æ”¶åˆ°ä¸€ä»½æ­·å²åˆ†æå ±å‘Šã€‚è«‹ä»¥æ­¤ç‚ºåŸºç¤ï¼Œçµåˆä»Šæ—¥æœ€æ–°æƒ…å ±ï¼Œé€²è¡Œã€Œæ»¾å‹•å¼ã€çš„æœªä¾†æƒ…å¢ƒæ¨¡æ“¬ã€‚"
            
            # å³ä½¿æœ‰èˆŠå ±å‘Šï¼Œä¹Ÿè¦æœæ–°çš„ï¼Œæ‰èƒ½ã€Œæ»¾å‹•ã€
            search = TavilySearchResults(max_results=15) 
            q_mix = f"{query} 2025 æœ€æ–°ç™¼å±•"
            results = search.invoke(q_mix)
            for i, res in enumerate(results):
                context_text += f"New Source {i+1}: {res.get('url')} | {str(res.get('content'))[:1500]}\n"
        else:
            # å…¨æ–°é–‹å§‹æ¨¡å¼
            search = TavilySearchResults(max_results=25)
            
            if mode == "V205": 
                q_mix = f"{query} analysis strategic report forecast 2025 implications trends"
                task_instruction = f"è«‹é‡å°è­°é¡Œã€Œ{query}ã€é€²è¡Œç¬¬ä¸€æ€§åŸç†èˆ‡æœªä¾†æƒ…å¢ƒæ¨¡æ“¬ã€‚"
            else: 
                q_mix = f"{query} 2025 æœ€æ–° å°ç£æ–°è çˆ­è­° æ‡¶äººåŒ… äº‹å¯¦æŸ¥æ ¸ è¬ è¨€ è‡ªç”±æ™‚å ± è¯åˆå ± ä¸­åœ‹æ™‚å ±"
                task_instruction = f"è«‹é‡å°è­°é¡Œã€Œ{query}ã€é€²è¡Œã€å…¨åŸŸæ·±åº¦è§£æã€‘ï¼Œæ•´åˆäº‹å¯¦æŸ¥æ ¸èˆ‡è§€é»åˆ†æã€‚"

            results = search.invoke(q_mix)
            for i, res in enumerate(results):
                context_text += f"Source {i+1}: {res.get('url')} | {str(res.get('content'))[:2500]}\n"

        # 2. æ€è€ƒéšæ®µ
        if mode == "V205":
            # [ä¿®æ­£] èªæ°£æ›´ä¸­æ€§ã€å­¸è¡“åŒ–
            system_prompt = f"""
            ä½ æ˜¯ä¸€ä½è³‡æ·±çš„è¶¨å‹¢é æ¸¬åˆ†æå¸«ã€‚{task_instruction}
            
            ã€åˆ†ææ ¸å¿ƒ (Foresight Framework)ã€‘ï¼š
            1. **ç¬¬ä¸€æ€§åŸç† (First Principles)**ï¼šå‰–æè­°é¡ŒèƒŒå¾Œçš„åº•å±¤é©…å‹•åŠ› (å¦‚ï¼šäººå£çµæ§‹ã€ç¶“æ¿Ÿèª˜å› ã€åœ°ç·£æ”¿æ²»)ã€‚
            2. **å¯èƒ½æ€§åœ“éŒ (Cone of Plausibility)**ï¼šæ¨æ¼”ä¸‰ç¨®æœªä¾†ç™¼å±•è·¯å¾‘ã€‚
                - **åŸºæº–æƒ…å¢ƒ (Baseline)**: è‹¥ç¾ç‹€æŒçºŒï¼Œæœ€å¯èƒ½çš„çµæœã€‚
                - **è½‰æŠ˜æƒ…å¢ƒ (Plausible)**: é—œéµè®Šæ•¸æ”¹è®Šå¾Œçš„åˆç†ç™¼å±•ã€‚
                - **æ¥µç«¯æƒ…å¢ƒ (Wild Card)**: ä½æ©Ÿç‡ä½†é«˜è¡æ“Šçš„é»‘å¤©éµäº‹ä»¶ã€‚

            ã€è©•åˆ†å®šç¾© (è¶¨å‹¢ç‰ˆ)ã€‘ï¼š
            1. Attack -> å½±éŸ¿é¡¯è‘—æ€§ (Significance)
            2. Division -> ç™¼å±•ä¸ç¢ºå®šæ€§ (Uncertainty)
            3. Impact -> æ™‚é–“ç·Šè¿«åº¦ (Urgency)
            4. Resilience -> ç³»çµ±è¤‡é›œåº¦ (Complexity)
            *Threat -> ç¶œåˆå½±éŸ¿åŠ› (Impact Index)

            ã€è¼¸å‡ºæ ¼å¼ã€‘ï¼š
            ### [DATA_SCORES]
            Threat: [åˆ†æ•¸]
            Attack: [åˆ†æ•¸]
            Impact: [åˆ†æ•¸]
            Division: [åˆ†æ•¸]
            Resilience: [åˆ†æ•¸]
            
            ### [DATA_TIMELINE]
            (æ ¼å¼ï¼šFuture-Date|é æ¸¬|äº‹ä»¶)
            
            ### [DATA_NARRATIVES]
            (ç¬¬ä¸€æ€§åŸç†,5)

            ### [REPORT_TEXT]
            (Markdown å ±å‘Š)
            # ğŸ¯ ç¬¬ä¸€æ€§åŸç†æ‹†è§£ (åº•å±¤é‚è¼¯)
            # ğŸ”® æœªä¾†æƒ…å¢ƒæ¨¡æ“¬ (å¯èƒ½æ€§åœ“éŒ)
            # ğŸ’¡ ç¶œåˆå»ºè­°èˆ‡è§€å¯Ÿ
            """
        else:
            system_prompt = f"""
            ä½ æ˜¯ä¸€ä½é›†ã€Œæ·±åº¦èª¿æŸ¥è¨˜è€…ã€èˆ‡ã€Œåª’é«”è­˜è®€å°ˆå®¶ã€æ–¼ä¸€èº«çš„æƒ…å ±åˆ†æå¸«ã€‚
            è«‹é‡å°è­°é¡Œã€Œ{query}ã€é€²è¡Œã€å…¨åŸŸæ·±åº¦è§£æã€‘ï¼Œæ•´åˆäº‹å¯¦æŸ¥æ ¸èˆ‡è§€é»åˆ†æã€‚
            
            ã€è©•åˆ†æŒ‡æ¨™ (0-100)ã€‘ï¼š
            1. Attack (å‚³æ’­ç†±åº¦): è¨è«–å¯†åº¦ã€‚
            2. Division (è§€é»åˆ†æ­§): é™£ç‡Ÿè½å·®ã€‚
            3. Impact (å½±éŸ¿æ½›åŠ›): æ”¿ç­–å½±éŸ¿ã€‚
            4. Resilience (è³‡è¨Šé€æ˜): æŸ¥æ ¸å®Œæ•´åº¦ã€‚
            *Threat (çˆ­è­°æŒ‡æ•¸): ç¶œåˆè©•ä¼°ã€‚

            ã€è¼¸å‡ºæ ¼å¼ (åš´æ ¼éµå®ˆ)ã€‘ï¼š
            ### [DATA_SCORES]
            Threat: [åˆ†æ•¸]
            Attack: [åˆ†æ•¸]
            Impact: [åˆ†æ•¸]
            Division: [åˆ†æ•¸]
            Resilience: [åˆ†æ•¸]
            
            ### [DATA_TIMELINE]
            (æ ¼å¼ï¼šYYYY-MM-DD|åª’é«”|æ¨™é¡Œ)
            
            ### [DATA_NARRATIVES]
            (æ ¼å¼ï¼šåŠ‡æœ¬åç¨±,å¼·åº¦1-5)
            {NARRATIVE_MODULES_STR}

            ### [REPORT_TEXT]
            (Markdown å ±å‘Š - è«‹ä½¿ç”¨ [Source X] å¼•ç”¨ä¾†æº)
            è«‹åŒ…å«ä»¥ä¸‹ç« ç¯€ï¼š
            1. **ğŸ“Š å…¨åŸŸç¾æ³æ‘˜è¦**
            2. **ğŸ” çˆ­è­°é»äº‹å¯¦æŸ¥æ ¸çŸ©é™£ (Fact-Check)**
            3. **âš–ï¸ åª’é«”è§€é»å…‰è­œå°ç…§**
            4. **ğŸ§  æ·±åº¦è­˜è®€èˆ‡åˆ©ç›Šåˆ†æ (Cui Bono)**
            5. **ğŸ¤” é—œéµåæ€**
            """

        llm = ChatGoogleGenerativeAI(model=model_name, temperature=0.1)
        prompt = ChatPromptTemplate.from_messages([("system", system_prompt), ("human", "{context_text}")])
        chain = prompt | llm
        response = call_gemini_with_retry(chain, {"context_text": context_text})
        return response.content, results

    except Exception as e:
        if "429" in str(e): return "API_LIMIT_ERROR", None
        return f"ERROR: {str(e)}", None

def parse_gemini_data(text):
    data = {"scores": {"Threat":0, "Attack":0, "Impact":0, "Division":0, "Resilience":0}, 
            "narratives": {}, "timeline": [], "report_text": ""}
    
    if not text or text.startswith("ERROR") or text == "API_LIMIT_ERROR":
        data["report_text"] = text
        return data

    for line in text.split('\n'):
        line = line.strip()
        for key in data["scores"]:
            if f"{key}:" in line:
                try: data["scores"][key] = int(re.search(r'\d+', line).group())
                except: pass
        
        if "|" in line and (line[0].isdigit() or "Future" in line):
            parts = line.split("|")
            if len(parts) >= 3:
                data["timeline"].append({
                    "date": parts[0].strip(),
                    "media": parts[1].strip(),
                    "event": parts[2].strip()
                })

    if "### [REPORT_TEXT]" in text:
        data["report_text"] = text.split("### [REPORT_TEXT]")[1].strip()
    elif "### REPORT_TEXT" in text:
        data["report_text"] = text.split("### REPORT_TEXT")[1].strip()
    else:
        match = re.search(r"(#+\s*.*æ‘˜è¦|1\.\s*.*æ‘˜è¦)", text)
        if match:
            data["report_text"] = text[match.start():]
        else:
            data["report_text"] = text

    return data

def generate_download_content(query, data, sources):
    timeline_str = "| æ—¥æœŸ | åª’é«” | äº‹ä»¶ |\n|---|---|---|\n"
    for item in data.get('timeline', []):
        timeline_str += f"| {item['date']} | {item['media']} | {item['event']} |\n"

    source_str = ""
    if sources:
        for i, s in enumerate(sources):
            source_str += f"{i+1}. [{s.get('content')[:60]}...]({s.get('url')})\n"

    full_content = f"""
# åˆ†æå ±å‘Šï¼š{query}

**åˆ†ææ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M')}

## 1. æ ¸å¿ƒæŒ‡æ¨™è©•ä¼°
* **ç¶œåˆæŒ‡æ•¸**: {data['scores'].get('Threat', 0)}
* **æŒ‡æ¨™ A**: {data['scores'].get('Attack', 0)}
* **æŒ‡æ¨™ B**: {data['scores'].get('Division', 0)}
* **æŒ‡æ¨™ C**: {data['scores'].get('Impact', 0)}
* **æŒ‡æ¨™ D**: {data['scores'].get('Resilience', 0)}

## 2. é—œéµç™¼å±•æ™‚åº
{timeline_str}

## 3. æ·±åº¦åˆ†æå…§å®¹
{data.get('report_text', 'ç„¡å ±å‘Šå…§å®¹')}

## 4. åƒè€ƒæ–‡ç»
{source_str}
"""
    return full_content

# ==========================================
# 4. ä»‹é¢ (UI)
# ==========================================
with st.sidebar:
    st.title("å¹³è¡¡å ±å°å„€è¡¨æ¿")
    
    analysis_mode = st.radio(
        "é¸æ“‡åˆ†æå¼•æ“ï¼š",
        options=["å…¨åŸŸæ·±åº¦è§£æ (Fusion)", "æœªä¾†ç™¼å±•æ¨æ¼”"],
        captions=["èåˆï¼šåª’é«”è­˜è®€ + äº‹å¯¦æŸ¥æ ¸ + åˆ©ç›Šåˆ†æ", "æ¨æ¼”ï¼šç¬¬ä¸€æ€§åŸç† + å¯èƒ½æ€§åœ“éŒ"],
        index=0
    )
    st.markdown("---")

    # [æ–°å¢] æ­·å²å ±å‘ŠåŒ¯å…¥å€ (æ»¾å‹•å¼è¿½è¹¤æ ¸å¿ƒ)
    with st.expander("ğŸ“‚ åŒ¯å…¥å‰æ¬¡å ±å‘Š (æŒçºŒè¿½è¹¤ç”¨)", expanded=False):
        past_report_input = st.text_area(
            "è«‹è²¼ä¸Šä¹‹å‰çš„åˆ†æå ±å‘Šå…§å®¹ (Markdown)ï¼š", 
            height=150, 
            placeholder="åœ¨æ­¤è²¼ä¸ŠèˆŠå ±å‘Šï¼Œç³»çµ±å°‡çµåˆä»Šæ—¥æ–°æƒ…å ±é€²è¡Œæ»¾å‹•åˆ†æ..."
        )

    st.markdown("---")
    blind_mode = st.toggle("ğŸ™ˆ ç›²æ¸¬æ¨¡å¼", value=False)
    
    with st.expander("ğŸ”‘ è¨­å®š", expanded=True):
        google_key = st.text_input("Gemini Key", value="", type="password")
        tavily_key = st.text_input("Tavily Key", value="", type="password")
        model_options = ["gemini-2.5-flash", "gemini-2.5-flash-lite", "gemini-2.5-pro"]
        selected_model = st.selectbox("æ¨¡å‹é¸æ“‡", model_options, index=0)

    with st.expander("ğŸ“– è©•åˆ†æŒ‡æ¨™å®šç¾© (å«å…¬å¼)", expanded=True):
        if "æœªä¾†" in analysis_mode:
            st.markdown("""
- **1. å½±éŸ¿é¡¯è‘—æ€§ (Significance)**
  - å…¬å¼ï¼šè­°é¡Œæ¬Šé‡(0.6) + å½±éŸ¿å±¤ç´š(0.4)
- **2. ç™¼å±•ä¸ç¢ºå®šæ€§ (Uncertainty)**
  - å…¬å¼ï¼šæœªçŸ¥è®Šæ•¸ / ç¸½è®Šæ•¸
- **3. æ™‚é–“ç·Šè¿«åº¦ (Urgency)**
  - å…¬å¼ï¼š1 / (å‰©é¤˜åæ‡‰æ™‚é–“)
- **4. ç³»çµ±è¤‡é›œåº¦ (Complexity)**
  - å…¬å¼ï¼šæ¶‰å…¥åˆ©å®³é—œä¿‚äººæ•¸é‡ * è€¦åˆåº¦
            """)
        else:
            st.markdown("""
- **1. å‚³æ’­ç†±åº¦ (Attack)**
  - å…¬å¼ï¼š(åª’é«”å ±å°é‡ * 0.6) + (ç¤¾ç¾¤è²é‡ * 0.4)
- **2. è§€é»åˆ†æ­§ (Division)**
  - å…¬å¼ï¼š(é™£ç‡Ÿå°ç«‹åº¦ * 0.7) + (æ¨¡ç³Šåº¦ * 0.3)
- **3. å½±éŸ¿æ½›åŠ› (Impact)**
  - å…¬å¼ï¼š(å—çœ¾è¦æ¨¡ * 0.5) + (æ™‚é–“ * 0.5)
- **4. è³‡è¨Šé€æ˜ (Resilience)**
  - å…¬å¼ï¼š(å®˜æ–¹è³‡æ–™ * 0.8) + (ç¬¬ä¸‰æ–¹æŸ¥æ ¸ * 0.2)
            """)

    st.markdown("### ğŸ“š ç›£æ¸¬è³‡æ–™åº«")
    cat_order = ["CHINA", "FARM", "BLUE", "GREEN", "OFFICIAL", "AGGREGATOR", "INTL", "JAPAN", "DIGITAL", "VIDEO"]
    for key in cat_order:
        if key in DB_MAP:
            label, _ = get_category_meta(key)
            with st.expander(f"{label} ({len(DB_MAP[key])})"):
                for domain in DB_MAP[key]:
                    st.markdown(f"- `{domain}`")

# ä¸»ç•«é¢
st.title(f"å…¨åŸŸè§€é»æœå°‹ - {analysis_mode.split(' ')[0]}")
query = st.text_input("è¼¸å…¥æ–°èè­°é¡Œ", placeholder="ä¾‹å¦‚ï¼šå·æ™®å°å°è¨€è«–")
search_btn = st.button("ğŸ” å•Ÿå‹•å…¨åŸŸæƒæ", type="primary")

if 'result' not in st.session_state: st.session_state.result = None
if 'sources' not in st.session_state: st.session_state.sources = None
if 'previous_report' not in st.session_state: st.session_state.previous_report = None

if search_btn and query:
    st.session_state.result = None 
    st.session_state.previous_report = None
    
    with st.spinner("ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨é€²è¡Œå…¨ç¶²æœå°‹èˆ‡æ™ºæ…§åˆ†æ..."):
        mode_code = "V205" if "æœªä¾†" in analysis_mode else "FUSION"
        
        # åˆ¤æ–·æ˜¯å¦ä½¿ç”¨åŒ¯å…¥çš„èˆŠå ±å‘Š
        report_context = past_report_input if past_report_input.strip() else None
        
        raw_text, sources = run_fusion_analysis(query, google_key, tavily_key, selected_model, mode=mode_code, context_report=report_context)
        
        parsed_data = parse_gemini_data(raw_text)
        st.session_state.result = parsed_data
        st.session_state.sources = sources
        st.rerun()

if st.session_state.result:
    data = st.session_state.result
    sources = st.session_state.sources
    
    if data["report_text"].startswith("ERROR") or data["report_text"] == "API_LIMIT_ERROR":
        st.error(f"âš ï¸ ç³»çµ±è¨Šæ¯ï¼š{data['report_text']}")
        if data["report_text"] == "API_LIMIT_ERROR":
            st.info("ğŸ’¡ å»ºè­°ï¼šè«‹ç¨ç­‰ 30 ç§’å¾Œå†è©¦ã€‚")
    else:
        # 1. å½©è‰²æ–‡å­—æŒ‡æ¨™
        scores = data.get("scores", {})
        c1, c2, c3, c4 = st.columns(4)
        
        if "æœªä¾†" in analysis_mode:
            metrics = [("å½±éŸ¿é¡¯è‘—æ€§", scores.get("Attack", 0)), ("ç™¼å±•ä¸ç¢ºå®šæ€§", scores.get("Division", 0)),
                       ("æ™‚é–“ç·Šè¿«åº¦", scores.get("Impact", 0)), ("ç³»çµ±è¤‡é›œåº¦", scores.get("Resilience", 0))]
        else:
            metrics = [("å‚³æ’­ç†±åº¦", scores.get("Attack", 0)), ("è§€é»åˆ†æ­§", scores.get("Division", 0)),
                       ("å½±éŸ¿æ½›åŠ›", scores.get("Impact", 0)), ("è³‡è¨Šé€æ˜", scores.get("Resilience", 0))]
        
        for col, (label, score) in zip([c1, c2, c3, c4], metrics):
            text_color = get_score_text_color(score)
            col.markdown(f"""
            <div class="metric-container">
                <p class="metric-score" style="color: {text_color};">{score}</p>
                <p class="metric-label">{label}</p>
            </div>
            """, unsafe_allow_html=True)
            
        # 2. æ™‚é–“è»¸è¡¨æ ¼ (åŠ å…¥ç‡ˆè™Ÿ)
        st.markdown("---")
        st.subheader("ğŸ“… é—œéµç™¼å±•æ™‚åº")
        if data["timeline"]:
            processed_data = []
            for item in data["timeline"]:
                media_name = item['media']
                cat = classify_media_name(media_name)
                emoji = "âšª"
                if cat == "CHINA": emoji = "ğŸ”´"
                elif cat == "BLUE": emoji = "ğŸ”µ"
                elif cat == "GREEN": emoji = "ğŸŸ¢"
                elif cat == "FARM": emoji = "ğŸŸ "
                elif cat == "VIDEO": emoji = "ğŸŸ£"
                elif cat == "INTL": emoji = "ğŸŒ"
                
                processed_data.append({
                    "æ—¥æœŸ": item['date'],
                    "ä¾†æº": f"{emoji} {media_name}",
                    "äº‹ä»¶æ‘˜è¦": item['event']
                })
            
            df = pd.DataFrame(processed_data)
            st.dataframe(df, width=1200, hide_index=True, use_container_width=True)
        else:
            st.info("ç„¡æ™‚é–“è»¸è³‡æ–™ã€‚")

        # 3. ç¶œåˆåˆ†æå ±å‘Š
        st.markdown("---")
        st.subheader("ğŸ“ ç¶œåˆåˆ†æå ±å‘Š")
        
        # è³‡è¨Šæ»¾å‹•æŒ‰éˆ• (æ›´å)
        if "æœªä¾†" not in analysis_mode:
            st.info("ğŸ’¡ æˆ°ç•¥å‡ç´šï¼šæ‚¨å¯ä»¥å°‡æ­¤åˆ†æçµæœä½œç‚ºåŸºç¤ï¼Œé€²è¡Œã€Œå¯èƒ½æ€§åœ“éŒã€æ¨æ¼”ã€‚")
            
            def on_roll_click(current_report):
                st.session_state.previous_report = current_report
                
            if st.button("ğŸš€ é€²è¡Œè³‡è¨Šæ»¾å‹•ï¼šå°‡æ­¤çµæœé¤µçµ¦æœªä¾†ç™¼å±•æ¨æ¼”", type="secondary", on_click=on_roll_click, args=(data["report_text"],)):
                with st.spinner("ğŸ”® æ­£åœ¨è®€å–å‰æ¬¡æƒ…å ±ï¼Œå•Ÿå‹•ç¬¬ä¸€æ€§åŸç†æ¨æ¼”..."):
                    raw_text, _ = run_fusion_analysis(query, google_key, tavily_key, selected_model, mode="V205", context_report=st.session_state.previous_report)
                    st.session_state.result = parse_gemini_data(raw_text)
                    st.rerun()

        st.markdown(data.get("report_text", "ç„¡åˆ†æå ±å‘Šã€‚"))
        
        # 4. ä¸‹è¼‰
        st.markdown("---")
        download_content = generate_download_content(query, data, sources)
        st.download_button(label="ğŸ“¥ ä¸‹è¼‰å ±å‘Š", data=download_content, file_name="Report.md", type="primary")

        # 5. åƒè€ƒæ–‡ç» (ç´”æ–‡å­—è¡¨æ ¼)
        st.markdown("---")
        st.subheader("ğŸ“š åƒè€ƒæ–‡ç»")
        if sources:
            df_data = []
            for i, s in enumerate(sources):
                domain = get_domain_name(s.get('url'))
                display_domain = "******" if blind_mode else domain
                title = s.get('content', '')[:80].replace("\n", " ") + "..."
                df_data.append({"ç·¨è™Ÿ": i+1, "åª’é«”/ç¶²åŸŸ": display_domain, "æ¨™é¡Œæ‘˜è¦": title, "åŸå§‹é€£çµ": s.get('url')})
            
            df = pd.DataFrame(df_data)
            st.dataframe(
                df, 
                column_config={"åŸå§‹é€£çµ": st.column_config.LinkColumn("é»æ“Šå‰å¾€")},
                hide_index=True,
                use_container_width=True
            )