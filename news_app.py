# ==========================================
# 0. å„ªå…ˆåŸ·è¡Œï¼šè­¦å‘Šå±è”½èˆ‡å¥—ä»¶è¨­å®š
# ==========================================
import warnings
import os
warnings.filterwarnings("ignore")
os.environ["on_bad_lines"] = "skip"

import streamlit as st
import re
import pandas as pd
import time
import requests
import json
import concurrent.futures
import random
from urllib.parse import urlparse
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_exponential
import streamlit.components.v1 as components
from tavily import TavilyClient

# ==========================================
# 1. åŸºç¤è¨­å®šèˆ‡ CSSæ¨£å¼ (èåˆèˆŠç‰ˆç¾å­¸)
# ==========================================
st.set_page_config(page_title="å…¨åŸŸè§€é»è§£æ V19.0", page_icon="âš–ï¸", layout="wide")

st.markdown("""
<style>
    .stButton button[kind="secondary"] { border: 2px solid #673ab7; color: #673ab7; font-weight: bold; }
    
    /* èˆŠç‰ˆæŒ‡æ¨™å¡ç‰‡æ¨£å¼ - å›æ­¸ï¼ */
    .metric-container {
        text-align: center; padding: 10px; background-color: #ffffff;
        border-radius: 8px; border: 1px solid #f0f0f0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05); transition: transform 0.2s;
        margin-bottom: 10px;
    }
    .metric-container:hover { transform: translateY(-2px); box-shadow: 0 4px 12px rgba(0,0,0,0.1); }
    .metric-score { font-size: 1.8em; font-weight: 700; margin: 0; line-height: 1.2; color: #1565c0; }
    .metric-label { font-size: 0.9em; font-weight: 500; margin-top: 5px; color: #666; }

    /* å ±å‘Šç´™å¼µé¢¨æ ¼ */
    .report-paper {
        background-color: #fdfbf7; color: #2c3e50; padding: 30px; 
        border-radius: 4px; margin-bottom: 15px; border: 1px solid #e0e0e0;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        font-family: "Georgia", "Cambria", "Times New Roman", serif;
        line-height: 1.8; font-size: 1.05rem;
    }
    
    .citation {
        font-size: 0.85em; color: #757575; background-color: #f0f0f0;
        padding: 2px 6px; border-radius: 4px; margin: 0 2px;
        font-family: sans-serif; border: 1px solid #e0e0e0; font-weight: 500;
    }

    .table-header-green { color: #2e7d32; font-weight: bold; font-size: 1.1em; border-bottom: 2px solid #2e7d32; margin-bottom: 10px; padding-bottom: 5px; }
    .table-header-blue { color: #1565c0; font-weight: bold; font-size: 1.1em; border-bottom: 2px solid #1565c0; margin-bottom: 10px; padding-bottom: 5px; }
    
    .mermaid-box { background-color: #ffffff; padding: 20px; border-radius: 8px; border: 1px solid #ddd; margin-top: 15px; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. è³‡æ–™åº«æ“´å…… (æ•´åˆèˆŠç‰ˆ DB_MAP)
# ==========================================
# æ“´å……å¾Œçš„å°ç£ç™½åå–® (å«ç¶²åª’)
TAIWAN_WHITELIST = [
    "udn.com", "ltn.com.tw", "chinatimes.com", "cna.com.tw", 
    "storm.mg", "setn.com", "ettoday.net", "tvbs.com.tw", 
    "mirrormedia.mg", "thenewslens.com", "upmedia.mg", 
    "rwnews.tw", "news.pts.org.tw", "ctee.com.tw", "businessweekly.com.tw",
    "news.yahoo.com.tw", "twreporter.org", "theinitium.com", "mindiworldnews.com", "vocus.cc"
]

CAMP_KEYWORDS = {
    "GREEN": ["è‡ªç”±", "ä¸‰ç«‹", "æ°‘è¦–", "æ–°é ­æ®¼", "é¡é€±åˆŠ", "æ”¾è¨€", "è³´æ¸…å¾·", "æ°‘é€²é»¨", "é’é³¥", "ä¸­å¤®ç¤¾"],
    "BLUE": ["è¯åˆ", "ä¸­æ™‚", "ä¸­åœ‹æ™‚å ±", "TVBS", "ä¸­å¤©", "é¢¨å‚³åª’", "åœ‹æ°‘é»¨", "è—ç‡Ÿ", "èµµå°‘åº·"],
    "RED": ["æ–°è¯", "äººæ°‘æ—¥å ±", "ç’°çƒ", "å¤®è¦–", "ä¸­è©•", "å›½å°åŠ"]
}

def get_domain_name(url):
    try: return urlparse(url).netloc.replace("www.", "")
    except: return ""

def format_citation_style(text):
    if not text: return ""
    def compress_match(match):
        nums = re.findall(r'\d+', match.group(0))
        unique_nums = sorted(list(set(nums)), key=int)
        return f'<span class="citation">Source {",".join(unique_nums)}</span>'
    pattern_compress = r'(\[Source \d+\](?:[,;]?\s*\[Source \d+\])*)'
    text = re.sub(pattern_compress, compress_match, text)
    return text

def is_chinese(text):
    return bool(re.search(r'[\u4e00-\u9fff]', text))

# ==========================================
# 3. æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„
# ==========================================

def search_cofacts(query):
    url = "https://cofacts-api.g0v.tw/graphql"
    graphql_query = """
    query ListArticles($text: String!) {
      ListArticles(filter: {q: $text}, orderBy: [{_score: DESC}], first: 3) {
        edges { node { text articleReplies(status: NORMAL) { reply { text type } } } }
      }
    }
    """
    try:
        response = requests.post(url, json={'query': graphql_query, 'variables': {'text': query}}, timeout=3)
        if response.status_code == 200:
            data = response.json()
            articles = data.get('data', {}).get('ListArticles', {}).get('edges', [])
            result_text = ""
            if articles:
                result_text += "ã€Cofacts æŸ¥æ ¸è³‡æ–™åº«ã€‘\n"
                for i, art in enumerate(articles):
                    node = art.get('node', {})
                    rumor = node.get('text', '')[:50]
                    replies = node.get('articleReplies', [])
                    if replies:
                        r_type = replies[0].get('reply', {}).get('type')
                        result_text += f"- è¬ è¨€: {rumor}... (åˆ¤å®š: {r_type})\n"
            return result_text
    except: return ""
    return ""

# V18.2 æœå°‹æ ¸å¿ƒ + V19 ç™½åå–®æ“´å……
def get_search_context(query, api_key_tavily, days_back, selected_regions, max_results, context_report=None):
    try:
        tavily = TavilyClient(api_key=api_key_tavily)
        
        search_params = {
            "search_depth": "advanced",
            "topic": "general",
            "days": days_back,
            "max_results": max_results
        }

        suffixes = []
        is_strict_taiwan = False
        
        # å€åŸŸåˆ¤æ–·é‚è¼¯
        if len(selected_regions) == 1 and "å°ç£" in selected_regions[0]:
            is_strict_taiwan = True
            suffixes.append("å°ç£ æ–°è" if is_chinese(query) else "Taiwan News")
        else:
            for r in selected_regions:
                if "å°ç£" in r: suffixes.append("å°ç£ æ–°è")
                if "äºæ´²" in r: suffixes.append("Asia News")
                if "æ­æ´²" in r: suffixes.append("Europe News")
                if "ç¾æ´²" in r: suffixes.append("US Americas News")
        
        if not suffixes: suffixes.append("News")
        search_q = f"{query} {' '.join(suffixes)}"
        if context_report: search_q += " analysis"
        
        search_params["query"] = search_q

        if is_strict_taiwan:
            search_params["include_domains"] = TAIWAN_WHITELIST
        else:
            search_params["exclude_domains"] = [
                "daum.net", "naver.com", "tistory.com",
                "espn.com", "bleacherreport.com", "cbssports.com", 
                "pinterest.com", "amazon.com", "tripadvisor.com"
            ]
        
        actual_query = search_params["query"]
        
        response = tavily.search(**search_params)
        results = response.get('results', [])
        context_text = ""
        
        if context_report:
            context_text += f"ã€æ­·å²èƒŒæ™¯ã€‘\n{context_report[:800]}...\n\n"
            
        context_text += "ã€æœ€æ–°ç¶²è·¯æƒ…å ±ã€‘(è«‹åš´æ ¼ä½¿ç”¨ [Source ID] å¼•ç”¨)\n"
        
        for i, res in enumerate(results):
            title = res.get('title', 'No Title')
            url = res.get('url', '#')
            pub_date = res.get('published_date', '')
            if not pub_date: pub_date = "Recent"
            else: pub_date = pub_date[:10]
            content = res.get('content', '')[:800]
            context_text += f"Source {i+1}: [Date: {pub_date}] [Title: {title}] {content} (URL: {url})\n"
            
        return context_text, results, actual_query, is_strict_taiwan
        
    except Exception as e:
        return f"Error: {str(e)}", [], "Error", False

@retry(stop=stop_after_attempt(2), wait=wait_exponential(multiplier=1, min=2, max=5), reraise=True)
def call_gemini(system_prompt, user_text, model_name, api_key):
    os.environ["GOOGLE_API_KEY"] = api_key
    llm = ChatGoogleGenerativeAI(model=model_name, temperature=0.2)
    prompt = ChatPromptTemplate.from_messages([("system", system_prompt), ("human", "{input}")])
    chain = prompt | llm
    return chain.invoke({"input": user_text}).content

def sanitize_mermaid_code(code):
    code = re.sub(r'```mermaid', '', code)
    code = re.sub(r'```', '', code)
    code = code.strip()
    lines = code.split('\n')
    clean_lines = []
    if not any(l.strip().startswith('graph') for l in lines):
        clean_lines.append("graph TD")
    for line in lines:
        if not line.strip(): continue
        def clean_label(match):
            text = match.group(1)
            safe_text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text) 
            return f'["{safe_text}"]'
        line = re.sub(r'\["(.*?)"\]', clean_label, line)
        line = re.sub(r'\[(.*?)\]', clean_label, line)
        line = re.sub(r'\((.*?)\)', clean_label, line)
        clean_lines.append(line)
    return "\n".join(clean_lines)

def render_mermaid(code):
    clean_code = sanitize_mermaid_code(code)
    html_code = f"""
    <div class="mermaid" style="text-align: center;">
    {clean_code}
    </div>
    <script type="module">
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
      mermaid.initialize({{ startOnLoad: true, theme: 'neutral', securityLevel: 'loose' }});
    </script>
    """
    components.html(html_code, height=600, scrolling=True)

# 3.3 æ ¸å¿ƒé‚è¼¯ï¼šæ•¸ä½æˆ°æƒ…å®¤ (èåˆèˆŠç‰ˆæœªä¾†å­¸æ¶æ§‹)
def run_council_of_rivals(query, context_text, model_name, api_key):
    prompts = {
        "A_SIDE": "ä½ æ˜¯ä¸€ä½ã€é«”åˆ¶å…§/ç¾ç‹€åˆ†æå¸«ã€‘ã€‚è«‹æ‰¾å‡ºæ”¯æŒç¾ç‹€ã€æ”¿ç­–åˆç†æ€§æˆ–å®˜æ–¹è§£é‡‹çš„è­‰æ“šã€‚å¿…é ˆå¼•ç”¨ä¾†æº [Source ID]ã€‚",
        "B_SIDE": "ä½ æ˜¯ä¸€ä½ã€æ”¹é©/æ‰¹åˆ¤æ´¾åˆ†æå¸«ã€‘ã€‚è«‹æ‰¾å‡ºè³ªç–‘ç¾ç‹€ã€çµæ§‹æ€§å•é¡Œæˆ–åå°æ„è¦‹çš„è­‰æ“šã€‚å¿…é ˆå¼•ç”¨ä¾†æº [Source ID]ã€‚",
        "CONTEXT": "ä½ æ˜¯ä¸€ä½ã€è„ˆçµ¡æ­·å²å­¸å®¶ã€‘ã€‚è«‹åˆ†æçˆ­è­°èƒŒå¾Œçš„æ·±å±¤æ­·å²æˆå› ã€ç¶“æ¿Ÿçµæ§‹æˆ–åœ°ç·£æ”¿æ²»å› ç´ ã€‚å¿…é ˆå¼•ç”¨ä¾†æº [Source ID]ã€‚",
        "FUTURIST": "ä½ æ˜¯ä¸€ä½ã€æœªä¾†è¶¨å‹¢é æ¸¬å¸«ã€‘ã€‚è«‹æ‡‰ç”¨ç¬¬ä¸€æ€§åŸç†èˆ‡å¯èƒ½æ€§åœ“éŒï¼Œæ¨æ¼”ä¸‰ç¨®æœªä¾†æƒ…å¢ƒï¼šåŸºæº–(Baseline)ã€è½‰æŠ˜(Plausible)ã€æ¥µç«¯(Wild Card)ã€‚"
    }
    
    opinions = {}
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_role = {
            executor.submit(call_gemini, prompt, context_text, model_name, api_key): role 
            for role, prompt in prompts.items()
        }
        for future in concurrent.futures.as_completed(future_to_role):
            role = future_to_role[future]
            try: opinions[role] = future.result()
            except Exception as e: opinions[role] = f"åˆ†æå¤±æ•—: {e}"

    editor_prompt = f"""
    ä½ æ˜¯ä¸€ä½å …æŒã€Œå¹³è¡¡å ±å°ã€çš„ç¸½ç·¨è¼¯ã€‚é‡å°ã€Œ{query}ã€ï¼Œè«‹ç”¢å‡ºä¸€ä»½æ·±åº¦å…¨è§£è®€ã€‚
    
    ã€è¼¸å…¥ç´ æã€‘ï¼š
    Aè§€é» (é«”åˆ¶): {opinions.get('A_SIDE')}
    Bè§€é» (æ‰¹åˆ¤): {opinions.get('B_SIDE')}
    è„ˆçµ¡: {opinions.get('CONTEXT')}
    æœªä¾†æ¨æ¼”: {opinions.get('FUTURIST')}
    
    ã€ä»»å‹™æŒ‡ä»¤ã€‘ï¼š
    1. **æ•´åˆåˆ†æ**ï¼šè«‹èåˆä¸Šè¿°è§€é»ï¼Œç”¢å‡ºä¸€ä»½çµæ§‹å®Œæ•´çš„å ±å‘Šã€‚
    2. **Mermaid è£½åœ–**ï¼šè«‹ç”Ÿæˆ Mermaid `graph TD` ä»£ç¢¼ï¼Œå±•ç¤ºå› æœéˆã€‚
    
    ã€è¼¸å‡ºæ ¼å¼ã€‘ï¼š
    ### [REPORT_TEXT]
    (Markdown å ±å‘Šå…§å®¹ï¼Œè«‹åŒ…å«ã€ŒğŸ”® æœªä¾†æƒ…å¢ƒæ¨¡æ“¬ã€ç« ç¯€)
    """
    final_report = call_gemini(editor_prompt, context_text, model_name, api_key)
    return opinions, final_report

# 3.4 æ ¸å¿ƒé‚è¼¯ï¼šè¼¿æƒ…å…‰è­œ (V18.2 ç‰ˆæœ¬)
def run_spectrum_analysis(query, context_text, model_name, api_key):
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½åª’é«”è­˜è®€å°ˆå®¶ã€‚è«‹é‡å°ã€Œ{query}ã€é€²è¡Œåª’é«”æ¡†æ¶åˆ†æã€‚
    
    ã€è©•åˆ†åš´æ ¼è¦å®šã€‘ï¼š
    1. **ç«‹å ´åˆ†æ•¸ (Stance)**ï¼š
       - **è² æ•¸ (-10 åˆ° -1)**ï¼šæ‰¹åˆ¤/åå°/æ³›ç¶ /ç¨æ´¾ã€‚
       - **é›¶ (0)**ï¼šä¸­ç«‹/ç´”äº‹å¯¦ã€‚
       - **æ­£æ•¸ (1 åˆ° 10)**ï¼šæ”¯æŒ/é«”åˆ¶/æ³›è—/çµ±æ´¾ã€‚
    2. **å¯ä¿¡åº¦ (Credibility)**ï¼š0-3 (è¾²å ´/æ¥µç«¯) ... 8-10 (æ¬Šå¨/æŸ¥æ ¸)ã€‚
    
    ã€è¼¸å‡ºæ ¼å¼ (è«‹ä¿æŒæ ¼å¼æ•´æ½”ï¼Œæ¯è¡Œä¸€ç­†ï¼Œä½¿ç”¨ | åˆ†éš”)ã€‘ï¼š
    ### [DATA_TIMELINE]
    (YYYY-MM-DD|åª’é«”|äº‹ä»¶æ¨™é¡Œ)
    
    ### [DATA_SPECTRUM]
    (é‡è¦ï¼šå¿…é ˆåŒ…å« 6 å€‹æ¬„ä½ï¼Œæ—¥æœŸè«‹å‹™å¿…å¾ Context ä¸­çš„ [Date: ...] æå–ï¼Œè‹¥ç„¡å‰‡å¡« Recent)
    ä¾†æºåç¨±|æ—¥æœŸ|æ–°èæ¨™é¡Œ|ç«‹å ´(-10~10)|å¯ä¿¡åº¦(0~10)|ç¶²å€
    
    ### [REPORT_TEXT]
    (Markdown å ±å‘Šï¼Œè«‹ä½¿ç”¨ `[Source 1, 3]` æ ¼å¼å¼•ç”¨)
    è«‹åŒ…å«ï¼šå…¨åŸŸç¾æ³æ‘˜è¦ã€åª’é«”æ¡†æ¶åˆ†æã€è­˜è®€å»ºè­°ã€‚
    """
    return call_gemini(system_prompt, context_text, model_name, api_key)

# 3.5 è³‡æ–™è§£æå™¨
def parse_gemini_data(text):
    data = {"timeline": [], "spectrum": [], "mermaid": "", "report_text": ""}
    
    mermaid_match = re.search(r"```mermaid\n(.*?)\n```", text, re.DOTALL)
    if mermaid_match:
        data["mermaid"] = mermaid_match.group(1)
        text = text.replace(mermaid_match.group(0), "")

    lines = text.split('\n')
    for line in lines:
        line = line.strip()
        if not line: continue
        
        if "|" in line and len(line.split("|")) >= 3 and (line[0].isdigit() or "20" in line):
            parts = line.split("|")
            if len(parts) == 3: 
                data["timeline"].append({"date": parts[0].strip(), "media": parts[1].strip(), "event": parts[2].strip()})
            
        if "|" in line and len(line.split("|")) >= 4 and not line.startswith("###") and not "YYYY" in line:
            parts = line.split("|")
            try:
                name = parts[0].strip()
                date = "Recent" 
                title = "é»æ“Šé–±è®€å ±å°"
                base_stance = 0
                base_cred = 0
                url = "#"
                
                if len(parts) >= 6:
                    date = parts[1].strip()
                    title = parts[2].strip()
                    base_stance = float(parts[3].strip())
                    base_cred = float(parts[4].strip())
                    url = parts[5].strip()
                elif len(parts) == 5:
                    title = parts[1].strip()
                    base_stance = float(parts[2].strip())
                    base_cred = float(parts[3].strip())
                    url = parts[4].strip()
                else:
                    base_stance = float(parts[1].strip())
                    base_cred = float(parts[2].strip())
                    url = parts[3].strip()

                final_stance = base_stance
                if any(k in name for k in CAMP_KEYWORDS["GREEN"]):
                    if final_stance > 0: final_stance = final_stance * -1
                    if final_stance == 0: final_stance = -5
                elif any(k in name for k in CAMP_KEYWORDS["BLUE"] + CAMP_KEYWORDS["RED"]):
                    if final_stance < 0: final_stance = final_stance * -1
                    if final_stance == 0: final_stance = 5
                
                data["spectrum"].append({
                    "source": name,
                    "date": date,
                    "title": title,
                    "stance": int(final_stance),
                    "credibility": int(base_cred), 
                    "url": url
                })
            except: pass

    report_split = re.split(r'###\s*\[?REPORT_TEXT\]?', text)
    if len(report_split) > 1:
        data["report_text"] = report_split[-1].strip()
    else:
        data["report_text"] = text

    return data

# [V19.0] æ¸²æŸ“è¡¨æ ¼ (æ”¯æ´ç›²æ¸¬æ¨¡å¼)
def render_spectrum_split(spectrum_data, blind_mode):
    if not spectrum_data: return
    
    # å¾©åˆ»èˆŠç‰ˆå¡ç‰‡é¢¨æ ¼çš„æŒ‡æ¨™é¡¯ç¤º (Mockup)
    c1, c2, c3 = st.columns(3)
    avg_cred = sum(i['credibility'] for i in spectrum_data) / len(spectrum_data) if spectrum_data else 0
    polarization = len([i for i in spectrum_data if abs(i['stance']) > 5])
    
    with c1: st.markdown(f'<div class="metric-container"><p class="metric-score" style="color:#2e7d32">{len(spectrum_data)}</p><p class="metric-label">åˆ†æç¯‡æ•¸</p></div>', unsafe_allow_html=True)
    with c2: st.markdown(f'<div class="metric-container"><p class="metric-score" style="color:#1565c0">{avg_cred:.1f}</p><p class="metric-label">å¹³å‡å¯ä¿¡åº¦</p></div>', unsafe_allow_html=True)
    with c3: st.markdown(f'<div class="metric-container"><p class="metric-score" style="color:#d32f2f">{polarization}</p><p class="metric-label">é«˜å°ç«‹æ–‡ç« </p></div>', unsafe_allow_html=True)

    green_list = []
    blue_list = []
    neutral_list = []
    
    for item in spectrum_data:
        if item['stance'] < 0: green_list.append(item)
        elif item['stance'] > 0: blue_list.append(item)
        else: neutral_list.append(item)
        
    green_list.sort(key=lambda x: x['credibility'], reverse=True)
    blue_list.sort(key=lambda x: x['credibility'], reverse=True)
    neutral_list.sort(key=lambda x: x['credibility'], reverse=True)
    
    def make_md_table(items):
        if not items: return "_ç„¡ç›¸é—œè³‡æ–™_"
        md = "| æ—¥æœŸ | åª’é«” | æ–°èæ¨™é¡Œ (é»æ“Šé–±è®€) | ç«‹å ´ | å¯ä¿¡åº¦ |\n|:---:|:---|:---|:---:|:---:|\n"
        for i in items:
            s = i['stance']
            if s < 0: s_txt = f"ğŸŸ¢ {s}"
            elif s > 0: s_txt = f"ğŸ”µ +{s}"
            else: s_txt = "âšª 0"
            
            c = i['credibility']
            if c >= 7: c_txt = f"ğŸŸ¢ {c}"
            elif c >= 4: c_txt = f"ğŸŸ¡ {c}"
            else: c_txt = f"ğŸ”´ {c}"
            
            t_text = i.get('title', 'é»æ“Šé–±è®€å ±å°')
            if len(t_text) > 25: t_text = t_text[:25] + "..."
            t_url = i.get('url', '#')
            t_date = i.get('date', 'Recent')
            
            # [V19.0] ç›²æ¸¬æ¨¡å¼è™•ç†
            display_source = "*****" if blind_mode else i['source']
            
            title_link = f"[{t_text}]({t_url})"
            md += f"| {t_date} | {display_source} | {title_link} | {s_txt} | {c_txt} |\n"
        return md

    c1, c2 = st.columns(2)
    with c1:
        st.markdown('<div class="table-header-green">ğŸŸ¢ æ³›ç¶  / æ‰¹åˆ¤é™£ç‡Ÿ (Green/Critical)</div>', unsafe_allow_html=True)
        st.markdown(make_md_table(green_list))
    with c2:
        st.markdown('<div class="table-header-blue">ğŸ”µ æ³›è— / é«”åˆ¶é™£ç‡Ÿ (Blue/Establishment)</div>', unsafe_allow_html=True)
        st.markdown(make_md_table(blue_list))
        
    if neutral_list:
        st.markdown("---")
        st.markdown('<div class="table-header-neutral">âšª ä¸­ç«‹ / å…¶ä»–è§€é» (Neutral/Other)</div>', unsafe_allow_html=True)
        st.markdown(make_md_table(neutral_list))

def render_timeline_markdown(timeline_data):
    if not timeline_data: return
    md = "| æ—¥æœŸ | åª’é«” | äº‹ä»¶/æ¨™é¡Œ |\n|:---:|:---|:---|\n"
    for item in timeline_data:
        md += f"| {item.get('date','')} | {item.get('media','')} | {item.get('event','')} |\n"
    st.markdown(md)

# 4. ä¸‹è¼‰åŠŸèƒ½
def convert_data_to_json(data):
    return json.dumps(data, indent=2, ensure_ascii=False)

def convert_data_to_md(data):
    return f"""
# å…¨åŸŸè§€é»åˆ†æå ±å‘Š
äº§ç”Ÿæ™‚é–“: {datetime.now()}

## 1. æ·±åº¦åˆ†æ
{data.get('report_text')}

## 2. æ™‚é–“è»¸
{pd.DataFrame(data.get('timeline')).to_markdown(index=False)}
    """

# ==========================================
# 5. UI
# ==========================================
with st.sidebar:
    st.title("å…¨åŸŸè§€é»è§£æ V19.0")
    analysis_mode = st.radio("é¸æ“‡æ¨¡å¼ï¼š", options=["ğŸ›¡ï¸ è¼¿æƒ…å…‰è­œ (Spectrum)", "ğŸ”® æœªä¾†ç™¼å±•æ¨æ¼” (Scenario)"], index=0)
    st.markdown("---")
    
    # [V19.0] æ¢å¾©ç›²æ¸¬æ¨¡å¼
    blind_mode = st.toggle("ğŸ™ˆ ç›²æ¸¬æ¨¡å¼ (éš±è—åª’é«”åç¨±)", value=False)
    
    with st.expander("ğŸ”‘ API è¨­å®š", expanded=True):
        if "GOOGLE_API_KEY" in st.secrets:
            st.success("âœ… Gemini Key Ready")
            google_key = st.secrets["GOOGLE_API_KEY"]
        else:
            google_key = st.text_input("Gemini Key", type="password")

        if "TAVILY_API_KEY" in st.secrets:
            st.success("âœ… Tavily Ready")
            tavily_key = st.secrets["TAVILY_API_KEY"]
        else:
            tavily_key = st.text_input("Tavily Key", type="password")
            
        model_name = st.selectbox("æ¨¡å‹", ["gemini-2.5-flash", "gemini-2.5-flash-lite", "gemini-2.5-pro"], index=0)
        
        search_days = st.selectbox(
            "æœå°‹æ™‚é–“ç¯„åœ (Time Range)",
            options=[3, 7, 14, 30, 90, 1825],
            format_func=lambda x: "ğŸ“… ä¸é™æ™‚é–“ (All Time)" if x == 1825 else f"è¿‘ {x} å¤©",
            index=2
        )
        
        max_results = st.slider("æœå°‹ç¯‡æ•¸ä¸Šé™", 10, 50, 20)
        selected_regions = st.multiselect(
            "æœå°‹è¦–è§’ (Region) - å¯è¤‡é¸",
            ["ğŸ‡¹ğŸ‡¼ å°ç£ (Taiwan)", "ğŸŒ äºæ´² (Asia)", "ğŸŒ æ­æ´² (Europe)", "ğŸŒ ç¾æ´² (Americas)"],
            default=["ğŸ‡¹ğŸ‡¼ å°ç£ (Taiwan)"]
        )

    with st.expander("ğŸ§  ç³»çµ±é‚è¼¯èªªæ˜", expanded=False):
        st.markdown("""
        **1. æœå°‹å„ªåŒ–**
        * **å°ç£æ¨¡å¼**: å•Ÿç”¨æ“´å……ç‰ˆç™½åå–® (å«æ•¸ä½ç¶²åª’)ã€‚
        * **ç›²æ¸¬æ¨¡å¼**: é®è”½ä¾†æºï¼Œå°ˆæ³¨å…§å®¹ã€‚
        
        **2. æœªä¾†æ¨æ¼” (Scenario)**
        * å¼•å…¥èˆŠç‰ˆã€Œç¬¬ä¸€æ€§åŸç†ã€èˆ‡ã€Œå¯èƒ½æ€§åœ“éŒã€æ¶æ§‹ã€‚
        """)

    with st.expander("ğŸ“‚ åŒ¯å…¥èˆŠæƒ…å ±", expanded=False):
        past_report_input = st.text_area("è²¼ä¸ŠèˆŠå ±å‘Š Markdownï¼š", height=100)
        
    st.markdown("### ğŸ“¥ å ±å‘ŠåŒ¯å‡º")
    if st.session_state.get('spectrum_result') or st.session_state.get('wargame_result'):
        active_data = st.session_state.get('wargame_result') if "Scenario" in analysis_mode else st.session_state.get('spectrum_result')
        if active_data:
            st.download_button("ä¸‹è¼‰ JSON", convert_data_to_json(active_data), "report.json", "application/json")
            st.download_button("ä¸‹è¼‰ Markdown", convert_data_to_md(active_data), "report.md", "text/markdown")

st.title(f"{analysis_mode.split(' ')[1]}")
query = st.text_input("è¼¸å…¥è­°é¡Œé—œéµå­—", placeholder="ä¾‹å¦‚ï¼šå°ç©é›»ç¾åœ‹è¨­å» çˆ­è­°")
search_btn = st.button("ğŸš€ å•Ÿå‹•åˆ†æå¼•æ“", type="primary")

if 'spectrum_result' not in st.session_state: st.session_state.spectrum_result = None
if 'wargame_result' not in st.session_state: st.session_state.wargame_result = None
if 'wargame_opinions' not in st.session_state: st.session_state.wargame_opinions = None
if 'sources' not in st.session_state: st.session_state.sources = None
if 'full_context' not in st.session_state: st.session_state.full_context = ""

if search_btn and query and google_key and tavily_key:
    st.session_state.spectrum_result = None
    st.session_state.wargame_result = None
    st.session_state.wargame_opinions = None
    
    with st.status("ğŸš€ å•Ÿå‹•å…¨åŸŸæƒæå¼•æ“ (V19.0)...", expanded=True) as status:
        
        days_label = "ä¸é™æ™‚é–“" if search_days == 1825 else f"è¿‘ {search_days} å¤©"
        regions_label = ", ".join([r.split(" ")[1] for r in selected_regions])
        st.write(f"ğŸ“¡ 1. é€£ç·š Tavily æœå°‹ (è¦–è§’: {regions_label} / æ™‚é–“: {days_label})...")
        
        context_text, sources, actual_query, is_strict_tw = get_search_context(query, tavily_key, search_days, selected_regions, max_results, past_report_input)
        st.session_state.sources = sources
        
        if is_strict_tw:
             st.info(f"ğŸ” å·²å•Ÿç”¨æ“´å……ç‰ˆå°ç£åª’é«”ç™½åå–® (Enhanced Whitelist)")
        else:
             st.info(f"ğŸ” æ··é¸æ¨¡å¼ï¼šå•Ÿç”¨åƒåœ¾éæ¿¾ (Smart Blacklist)")
        
        st.write("ğŸ›¡ï¸ 2. æŸ¥è©¢ Cofacts è¬ è¨€è³‡æ–™åº« (API)...")
        cofacts_txt = search_cofacts(query)
        if cofacts_txt:
            context_text += f"\n{cofacts_txt}\n"
        st.session_state.full_context = context_text
        
        st.write("ğŸ§  3. AI é€²è¡Œæ·±åº¦é–±è®€èˆ‡åˆ†æ...")
        
        if "Spectrum" in analysis_mode:
            raw_report = run_spectrum_analysis(query, context_text, model_name, google_key)
            st.session_state.spectrum_result = parse_gemini_data(raw_report)
        else:
            st.write("âš”ï¸ 4. å¬é–‹è™›æ“¬æˆ°æƒ…æœƒè­° (åŠ å…¥æœªä¾†å­¸æ¨æ¼”)...")
            opinions, raw_report = run_council_of_rivals(query, context_text, model_name, google_key)
            st.session_state.wargame_opinions = opinions
            st.session_state.wargame_result = parse_gemini_data(raw_report)
            
        status.update(label="âœ… åˆ†æå®Œæˆ", state="complete", expanded=False)
        
    st.rerun()

if st.session_state.spectrum_result and "Spectrum" in analysis_mode:
    data = st.session_state.spectrum_result
    
    # [V19.0] å‚³å…¥ç›²æ¸¬ç‹€æ…‹
    if data.get("spectrum"):
        st.markdown("### ğŸ“Š è¼¿è«–é™£åœ°åˆ†æè¡¨ (Spectrum Table)")
        render_spectrum_split(data["spectrum"], blind_mode)
    
    if data.get("timeline"):
        st.markdown("### ğŸ“… è­°é¡Œç™¼å±•æ™‚é–“è»¸ (News Timeline)")
        render_timeline_markdown(data["timeline"])

    st.markdown("### ğŸ“ åª’é«”è­˜è®€å ±å‘Š")
    formatted_text = format_citation_style(data.get("report_text", ""))
    st.markdown(f'<div class="report-paper">{formatted_text}</div>', unsafe_allow_html=True)
    
    st.markdown("---")
    st.info("è¦ºå¾—è­°é¡Œéœ€è¦æ›´æ·±åº¦æ¨æ¼”ï¼Ÿè«‹é»æ“Šä¸‹æ–¹æŒ‰éˆ•ã€‚")
    if st.button("ğŸš€ åŸºæ–¼æ­¤æƒ…å ±å•Ÿå‹•æœªä¾†ç™¼å±•æ¨æ¼” (Scenario)", type="primary"):
        if st.session_state.full_context:
            with st.status("âš”ï¸ é€²è¡Œå¤šè¦–è§’æ¨æ¼”...", expanded=True) as status:
                st.write("1. å•Ÿå‹•è™›æ“¬å¹•åƒšç¾¤...")
                opinions, raw_report = run_council_of_rivals(query, st.session_state.full_context, model_name, google_key)
                st.session_state.wargame_opinions = opinions
                st.session_state.wargame_result = parse_gemini_data(raw_report)
                status.update(label="âœ… æ¨æ¼”å®Œæˆ", state="complete", expanded=False)
                st.rerun()

if st.session_state.wargame_result:
    st.divider()
    st.markdown(f"<h2 style='text-align: center;'>âš”ï¸ æœªä¾†ç™¼å±•æ¨æ¼”ï¼š{query}</h2>", unsafe_allow_html=True)
    
    ops = st.session_state.wargame_opinions
    if ops:
        c_a, c_b, c_ctx = st.columns(3)
        with c_a:
            st.markdown(f'<div class="perspective-box box-blue"><b>ğŸ”µ é«”åˆ¶/ç¾ç‹€è¦–è§’</b><br>{ops.get("A_SIDE")[:150]}...</div>', unsafe_allow_html=True)
            with st.popover("æŸ¥çœ‹å®Œæ•´è«–è¿°"): 
                st.markdown(format_citation_style(ops.get("A_SIDE")), unsafe_allow_html=True)
        with c_b:
            st.markdown(f'<div class="perspective-box box-green"><b>ğŸŸ¢ æ‰¹åˆ¤/æ”¹é©è¦–è§’</b><br>{ops.get("B_SIDE")[:150]}...</div>', unsafe_allow_html=True)
            with st.popover("æŸ¥çœ‹å®Œæ•´è«–è¿°"): 
                st.markdown(format_citation_style(ops.get("B_SIDE")), unsafe_allow_html=True)
        with c_ctx:
            st.markdown(f'<div class="perspective-box box-neutral"><b>ğŸ“œ æ·±å±¤è„ˆçµ¡åˆ†æ</b><br>{ops.get("CONTEXT")[:150]}...</div>', unsafe_allow_html=True)
            with st.popover("æŸ¥çœ‹å®Œæ•´è«–è¿°"): 
                st.markdown(format_citation_style(ops.get("CONTEXT")), unsafe_allow_html=True)

    data_wg = st.session_state.wargame_result
    
    if data_wg.get("mermaid"):
        st.markdown("### ğŸ•¸ï¸ ç³»çµ±å› æœè¿´è·¯åœ– (System Dynamics)")
        st.markdown('<div class="mermaid-box">', unsafe_allow_html=True)
        render_mermaid(data_wg["mermaid"])
        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.warning("âš ï¸ ç³»çµ±æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„å› æœåœ–ä»£ç¢¼ã€‚")

    st.markdown("### ğŸ“ ç¸½ç·¨è¼¯æ·±åº¦æ±ºç­–å ±å‘Š")
    formatted_report = format_citation_style(data_wg.get("report_text", ""))
    st.markdown(f'<div class="report-paper">{formatted_report}</div>', unsafe_allow_html=True)

if st.session_state.sources:
    st.markdown("---")
    st.markdown("### ğŸ“š å¼•ç”¨æ–‡ç»åˆ—è¡¨")
    md_table = "| ç·¨è™Ÿ | åª’é«”/ç¶²åŸŸ | æ¨™é¡Œæ‘˜è¦ | é€£çµ |\n|:---:|:---|:---|:---|\n"
    for i, s in enumerate(st.session_state.sources):
        domain = get_domain_name(s.get('url'))
        # é…åˆç›²æ¸¬æ¨¡å¼éš±è—ä¾†æº
        if blind_mode: domain = "*****"
        
        title = s.get('title', 'No Title')
        if len(title) > 60: title = title[:60] + "..."
        url = s.get('url')
        md_table += f"| **{i+1}** | `{domain}` | {title} | [é»æ“Š]({url}) |\n"
    st.markdown(md_table)
